---
weight: 2
title: "Camera components"
math: mathjax
---

# Camera components

## Hardware components

Components in a camera:

- **Lens:** Determines focus, depth of field, and field of view.
- **Image Sensor:** Translates optical images into electronic signals, common types:
  - **CCD (Charge-Coupled Device):** Known for high-quality, low-noise images but consumes more power.
  - **CMOS (Complementary Metal-Oxide Semiconductor):** More power-efficient and affordable but traditionally lower in quality.
- **Shutters:** Controls exposure; includes mechanical and electronic shutters.
  - **Rolling Shutter:** Allows continuous photon gathering, increasing sensitivity but introducing motion artifacts.
  - **Global Shutter:** Captures a full image at once, reducing motion distortion.

## Sensors

**CCD vs. CMOS:**

- CCD sensors are preferred for high-resolution applications but are power-intensive.
- CMOS sensors are cheaper, consume less power, and are improving in quality.

**Noise Types:**

- **Temporal Noise:** Random fluctuations over time, reduced by averaging.
- **Spatial Noise:** Variations across the sensor array, related to manufacturing.

## Lenses

Types of lenses:

- **Standard Lenses**: Common in everyday applications, providing a balance of image size and field of view.

- **Telephoto Lenses**: Provide magnification, suitable for distant objects but with a narrower field of view.

- **Wide-angle Lenses**: Capture larger fields of view, useful for confined spaces.

- **Telecentric Lenses**: Maintain a constant magnification, minimizing perspective distortion, especially useful in machine vision applications where precise measurements are required.

Other lens related definitions:

- **Depth of Field (DOF)** is the range of distances in front of the camera where things look sharp. If you have a large depth of field, both near and far objects appear clear. With a small depth of field, only the subject is in focus, and the background is blurred.

- **Working Distance** is how far the camera is from the object it's capturing. A longer working distance can make it easier to keep things in focus, while a shorter working distance brings the camera closer to the object.

- **Field of View (FOV)** is the area the camera can “see” in one shot. A wide field of view means the camera can capture more of the scene, while a narrow field of view focuses on a smaller part of the scene.

- **Resolution** is how much detail the camera can capture. Higher resolution means you can see more detail and smaller features in the image.

## Spectral Sensitivity

**Spectral Sensitivity** refers to the responsiveness of a sensor to different wavelengths of light, influencing how effectively a camera captures different colors and intensities. Human eye spectral sensitivity differs significantly from image sensors like CMOS and CCD, which have unique sensitivities across wavelengths due to sensor material and design.

## Bayer Filter

The **Bayer Filter** is a color filter array commonly used in digital image sensors, which arranges color filters in a grid (usually red, green, and blue) over the sensor pixels. This layout allows interpolation to reconstruct full-color images from sensor data, with green pixels typically twice as numerous as red or blue to match human vision sensitivity.

## Fill Factor

**Fill Factor** measures the ratio of a sensor's light-sensitive area to its total area. Higher fill factors mean more efficient light capture. Techniques like microlenses are used to increase fill factors by directing more light onto the active area of each pixel, especially in CMOS sensors, where architectural constraints can reduce fill factor.

## Readout Modes

**Readout Modes** determine how image data is processed from the sensor. Common modes include:

- **Interlaced Scan**: Captures odd and even fields separately to reduce flicker but can cause motion artifacts.
- **Progressive Scan**: Sequentially reads each row, providing a full frame in one go, which is beneficial for moving subjects.

## Types of Illumination

**Backlighting**:

- Creates high contrast by illuminating objects from behind, casting them as dark silhouettes on a bright background.
- Ideal for applications like presence/absence detection and edge measurement.

**Diffuse (Full Bright Field) Lighting**:

- Uses a dome or on-axis light to produce uniform, non-directional light, minimizing shadows.
- Best for curved or specular surfaces, enhancing textures and features without glare.

**Bright Field (Directional) Lighting**:

- Employs directional lighting to highlight surface details, increasing contrast for textured surfaces.
- Often used off-axis to avoid hotspots in highly reflective objects.

**Dark Field Lighting**:

- Lights the object from low angles, illuminating only edges or surface imperfections.
- Suitable for detecting scratches, cracks, or embossed features, as only reflective imperfections are highlighted.

**Strobe Lighting**:

- Uses high-intensity, pulsed light to capture fast-moving objects, freezing motion for clear imaging.
- Common in high-speed inspections, where precise, short-duration light pulses are necessary.

Each of these lighting techniques is chosen based on the surface characteristics, texture, and reflectivity of the object, enhancing specific features for machine vision applications.

## Lens Formulas

### Magnification formula

To calculate the **magnification** of an image:

{{< katex >}}
\text{Magnification} = \frac{\text{Sensor Size of the Camera}}{\text{Field of View}}
{{< /katex >}}

### Focal Length Formula

To estimate the required **focal length** based on magnification and working distance:

{{< katex >}}
\text{Focal Length} = \frac{\text{Magnification} \times \text{Working Distance}}{1 + \text{Magnification}}
{{< /katex >}}

### Pinhole camera formula

{{< katex >}}
\frac{h'}{s'} = \frac{h}{s}
{{< /katex >}}

{{< katex >}} h {{< /katex >}} is the object height

{{< katex >}} h' {{< /katex >}} is the image height

{{< katex >}} s {{< /katex >}} is the object distance from the pinhole,

{{< katex >}} s' {{< /katex >}} is the image distance from the pinhole.

### Gaussian Optics Formula

{{< katex >}}
\frac{1}{s} + \frac{1}{s'} = \frac{1}{f}
{{< /katex >}}

{{< katex >}} s {{< /katex >}} is the object distance from the lens,

{{< katex >}} s' {{< /katex >}} is the image distance,

{{< katex >}} f {{< /katex >}} is the focal length of the lens.

### Lens Refraction (Snell's Law)

{{< katex >}}
n_1 \sin(\theta_1) = n_2 \sin(\theta_2)
{{< /katex >}}

{{< katex >}} n_1 {{< /katex >}} and {{< katex >}} n_2 {{< /katex >}} are the refractive indices of two media,

{{< katex >}} \theta_1 {{< /katex >}} and {{< katex >}} \theta_2 {{< /katex >}} are the angles of incidence and refraction.

## Example question

**Question**

It is required to image 5 cm wide object using a CCD camera, whose sensor measures
8.8 x 6.6 mm, at a distance of 0.5 m. What focal length lens should you choose?

**Answer**

To calculate the focal length lens required to image a 5 cm wide object onto a CCD camera sensor, we can use the Gaussian lens formula:

    Object Width (Field of View) = 5 cm = 50 mm
    Sensor Width = 8.8 mm
    Working Distance = 0.5 m = 500 mm

Using the magnification formula:

{{< katex >}}
\text{Magnification} = \frac{\text{Sensor Size of the Camera}}{\text{Field of View}}
{{< /katex >}}

Substitute the values:

{{< katex display=true >}}
\text{Magnification} = \frac{8.8}{50} = 0.176
{{< /katex >}}

Using the focal length formula:

{{< katex display=true class="optional" >}}
\text{Focal Length} = \frac{\text{Magnification} \times \text{Working Distance}}{1 + \text{Magnification}}
{{< /katex >}}

Substitute the values:

{{< katex display=true >}}
\text{Focal Length} = \frac{0.176 \times 500}{1 + 0.176}
{{< /katex >}}

Answer:

{{< katex >}}
\text{Focal Length} = \frac{88}{1.176} \approx 74.83 \, \text{mm}
{{< /katex >}}