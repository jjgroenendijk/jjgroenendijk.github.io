---
weight: 13
title: "Feature Extraction"
---

# Feature Extraction

Feature extraction identifies and represents key attributes or features of an image, such as shape, texture, intensity, and motion. Shape features might include area and perimeter, while texture features could involve patterns and smoothness within the image. These attributes enable detailed analysis and classification of image content. It transforms visual data into numerical representations, enabling tasks like classification, recognition, and analysis. This step is critical in computer vision and image processing for simplifying and analyzing image content.

## Purpose and Techniques

The goal is to transform segmented objects into compact representations that describe their primary characteristics. Features can be based on:

- Intensity
- Shape
- Texture
- Motion

Feature extraction often requires prior segmentation to isolate objects of interest.

## Feature Vectors and Spaces

A feature vector is an array encoding numerical or symbolic data about an object. For example, a symbolic feature could be a categorical label such as 'circle' or 'square,' representing the shape of an object. This representation resides in a multidimensional feature space, making it easier to analyze object relationships. For example:

- A square can be described by its area and perimeter.
- A feature space allows visualization and comparison between different objects.

## Invariance and Robustness

Feature design often includes invariance to:

- **Rotation:** Recognition regardless of orientation.
- **Scaling:** Identifying objects at different sizes.
- **Translation:** Detecting objects regardless of position.

Invariance ensures robust performance across diverse conditions.

## Binary Object Features

In binary images, features include:

- **Area:** The total number of pixels in an object.
- **Centroid:** The object's center of mass, calculated as:
  {{< katex display=true >}}
  \bar{x} = \frac{1}{A} \sum_{x,y} x \cdot O(x, y), \quad \bar{y} = \frac{1}{A} \sum_{x,y} y \cdot O(x, y)
  {{< /katex >}}
  where {{< katex >}}A{{< /katex >}} is the object's area, and {{< katex >}}O(x, y){{< /katex >}} indicates whether a pixel belongs to the object.
- **Moments:** Quantify spatial distribution of pixel intensities. Moments are defined as:
  {{< katex display=true >}}
  m_{pq} = \sum_{x=0}^{M-1} \sum_{y=0}^{N-1} x^p y^q f(x, y)
  {{< /katex >}}
- **Central Moments:** Translation-invariant moments defined as:
  {{< katex display=true >}}
  \mu_{pq} = \sum_{x=0}^{M-1} \sum_{y=0}^{N-1} (x - \bar{x})^p (y - \bar{y})^q f(x, y)
  {{< /katex >}}
- **Normalized Central Moments:** Scale-invariant moments, calculated as:
  {{< katex display=true >}}
  n_{pq} = \frac{\mu_{pq}}{\mu_{00}^\gamma}, \quad \gamma = \frac{p + q}{2} + 1
  {{< /katex >}}
- **Axis of Least Second Moment:** Determines orientation of the object using the minimum spread of intensity.
- **Projections:** Summarize distribution of pixels along specific axes.
- **Euler Number:** Measures topology of the object:
  {{< katex display=true >}}
  E = \text{Number of Objects} - \text{Number of Holes}
  {{< /katex >}}
- **Perimeter:** Total length of the object's boundary.
- **Thinness Ratio:** Indicates roundness:
  {{< katex display=true >}}
  T_i = \frac{4\pi A_i}{P_i^2}
  {{< /katex >}}
- **Eccentricity:** Quantifies elongation:
  {{< katex display=true >}}
  e = \frac{a}{b}
  {{< /katex >}}
- **Aspect Ratio:** Ratio of width to height:
  {{< katex display=true >}}
  \text{Aspect Ratio} = \frac{\text{Width}}{\text{Height}}
  {{< /katex >}}
- **Elongatedness:** Measures how stretched an object is:
  {{< katex display=true >}}
  \text{Elongatedness} = \frac{\text{Perimeter}^2}{4 \pi \cdot \text{Area}}
  {{< /katex >}}

## Histogram-Based Features

Histograms provide statistical summaries of pixel intensities within an image or region. These features are simple yet powerful for analyzing intensity distributions. Common histogram-based features include:

- **Mean Intensity:** The average pixel value:
  {{< katex display=true >}}
  \text{Mean} = \frac{1}{N} \sum_{i=1}^{N} I_i
  {{< /katex >}}
- **Standard Deviation:** Measures the spread of pixel intensities:
  {{< katex display=true >}}
  \sigma = \sqrt{\frac{1}{N} \sum_{i=1}^{N} (I_i - \text{Mean})^2}
  {{< /katex >}}
- **Skewness:** Indicates the asymmetry of the histogram.
- **Kurtosis:** Describes the sharpness or flatness of the histogram.

These features are particularly useful for tasks like contrast analysis, thresholding, and classification.

### Texture Features

Texture features describe the spatial arrangement of pixel intensities, capturing patterns that represent surface properties. Common methods include:

#### Gray-Level Co-Occurrence Matrix (GLCM)

GLCM captures how often pairs of pixel intensities occur at a specific distance and angle. For instance, in medical image analysis, GLCM is used to analyze tissue textures, aiding in the identification of abnormalities like tumors or fibrosis. Features derived from GLCM include:

- **Contrast:** Measures the intensity difference between pixels:
  {{< katex display=true >}}
  \text{Contrast} = \sum_{i,j} |i - j|^2 \cdot P(i,j)
  {{< /katex >}}
- **Correlation:** Indicates how correlated pixel intensities are:
  {{< katex display=true >}}
  \text{Correlation} = \frac{\sum_{i,j} (i \cdot j \cdot P(i,j)) - \mu_i \mu_j}{\sigma_i \sigma_j}
  {{< /katex >}}
- **Energy:** Measures uniformity:
  {{< katex display=true >}}
  \text{Energy} = \sum_{i,j} P(i,j)^2
  {{< /katex >}}
- **Homogeneity:** Captures the closeness of pixel values:
  {{< katex display=true >}}
  \text{Homogeneity} = \sum_{i,j} \frac{P(i,j)}{1 + |i - j|}
  {{< /katex >}}

#### Local Binary Patterns (LBP)

LBP encodes texture by thresholding a pixelâ€™s neighborhood. A binary pattern is generated, representing the relationship between a pixel and its neighbors. LBP is rotation-invariant and robust to illumination changes.

#### Gabor Filters

Gabor filters extract texture by analyzing frequency and orientation. A Gabor filter is defined as:
{{< katex display=true >}}
G(x, y; \lambda, \theta, \psi, \sigma, \gamma) = \exp\left(-\frac{x'^2 + \gamma^2 y'^2}{2 \sigma^2}\right) \cos\left(2 \pi \frac{x'}{\lambda} + \psi\right)
{{< /katex >}}
Where {{< katex >}}x'{{< /katex >}} and {{< katex >}}y'{{< /katex >}} are rotated coordinates, {{< katex >}}\lambda{{< /katex >}} is the wavelength, {{< katex >}}\theta{{< /katex >}} is the orientation, and {{< katex >}}\gamma{{< /katex >}} controls the scale.

### Boundary Descriptors (Contour-Based)

Boundary descriptors focus on the outline of an object, providing insights into its shape. For example, in character recognition, boundary descriptors can help identify letters by analyzing the unique contours and edges of each character. These include:

- **Perimeter:** Total length of the boundary.
- **Curvature:** How sharply the boundary changes direction.
- **Signatures:** One-dimensional representations of the boundary, such as radial distance from the centroid.

### Signatures

A signature is a one-dimensional representation of the boundary, commonly plotting radial distance from the centroid:
{{< katex display=true >}}
R(\theta) = \sqrt{(x - \bar{x})^2 + (y - \bar{y})^2}
{{< /katex >}}
Where {{< katex >}}\theta{{< /katex >}} is the angle, and {{< katex >}}x, y{{< /katex >}} are boundary points.
